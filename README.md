ğŸ“˜ README â€” Architecture & Pipeline du Chatbot PadelReference (Phase 1)
ğŸ§© Objectif du projet

DÃ©velopper un backend FastAPI reliÃ© Ã  un widget Tiledesk permettant :

de rÃ©pondre automatiquement aux questions frÃ©quentes du SAV

dâ€™identifier les intentions utilisateur (Â« intents Â»)

dâ€™extraire des rÃ©ponses depuis un corpus de FAQ

dâ€™utiliser lâ€™IA uniquement lorsque nÃ©cessaire

dâ€™envoyer une rÃ©ponse claire et fiable au chatbot

Phase 1 = RÃ©duction de 30â€“40% du SAV sur les questions â€œpoubellesâ€.

ğŸ—ï¸ Architecture du projet
padelref/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚     â””â”€â”€ chatbot.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚     â”œâ”€â”€ keyword_matcher.py
â”‚   â”‚     â”œâ”€â”€ intent_classifier.py
â”‚   â”‚     â”œâ”€â”€ faq_responder.py
â”‚   â”‚     â””â”€â”€ fallback.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚     â”œâ”€â”€ config.py
â”‚   â”‚     â””â”€â”€ prompts.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚     â”œâ”€â”€ loader.py
â”‚   â”‚     â””â”€â”€ logger.py
â”‚   â””â”€â”€ data/
â”‚         â”œâ”€â”€ faq_corpus.json
â”‚         â””â”€â”€ intents.json
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .envrc
â””â”€â”€ README.md

ğŸ“‚ RÃ´le de chaque fichier
1) main.py

Point dâ€™entrÃ©e FastAPI.

Installe le routeur principal (/tiledesk/message).

Ajoute CORS + healthcheck.

â¡ï¸ Câ€™est la porte du backend.

2) routers/chatbot.py

Le cerveau du pipeline.

Il gÃ¨re :

la rÃ©ception du message venant de Tiledesk

lâ€™extraction du message utilisateur

lâ€™appel successif de :

keyword matcher

intent classifier (LLM)

FAQ responder (LLM)

fallback (LLM)

lâ€™envoi de la rÃ©ponse finale Ã  Tiledesk

â¡ï¸ Câ€™est ici que tout sâ€™enchaÃ®ne.

3) services/keyword_matcher.py

Outil rapide pour dÃ©tecter un intent via mots-clÃ©s.

Exemples :

"livraison", "expÃ©dition" â†’ intent = livraison

"garantie", "cassÃ©e", "fissure" â†’ intent = garantie

â¡ï¸ Solution rapide, non IA, qui couvre 80% des cas.

4) services/intent_classifier.py

Si le keyword matcher ne trouve rien :

ğŸ‘‰ on appelle lâ€™IA (GPT-4o-mini)
pour classifier le message parmi les intents :

livraison

commande

garantie

retour_colis

produits

paiement

fallback
etc.

Le LLM reÃ§oit le PROMPT_INTENT_CLASSIFIER, et retourne un seul mot : le nom de lâ€™intent.

â¡ï¸ IA utilisÃ©e uniquement pour: classification sÃ©mantique fine.

5) services/faq_responder.py

Une fois lâ€™intent identifiÃ© :

on rÃ©cupÃ¨re les questions/rÃ©ponses associÃ©es dans faq_corpus.json

on envoie un message Ã  lâ€™IA pour quâ€™elle sÃ©lectionne la rÃ©ponse la plus adaptÃ©e
â†’ avec seulement les infos du corpus
â†’ sans inventer ni halluciner

â¡ï¸ Lâ€™IA ne gÃ©nÃ¨re pas du contenu libre â†’ elle choisit parmi un corpus.

6) services/fallback.py

Si :

pas dâ€™intent fiable

pas de rÃ©ponse dans la FAQ

message hors scope

Alors :
ğŸ‘‰ lâ€™IA gÃ©nÃ¨re une rÃ©ponse courte, neutre, utile
ğŸ‘‰ invite Ã  reformuler ou Ã  contacter le support
ğŸ‘‰ sans halluciner

â¡ï¸ Câ€™est une sÃ©curitÃ©.

7) core/prompts.py

Contient tous les prompts systÃ¨me :

SYSTEM_PROMPT

PROMPT_INTENT_CLASSIFIER

PROMPT_FAQ

PROMPT_FALLBACK

â¡ï¸ Câ€™est la personnalitÃ© et la stratÃ©gie de lâ€™assistant.

8) core/config.py

Charge les variables dâ€™environnement depuis .envrc (direnv).

â¡ï¸ SÃ©curise la clÃ© OpenAI.

9) utils/loader.py

Charge les fichiers JSON au dÃ©marrage :

faq_corpus.json

intents.json

â¡ï¸ Centralise les donnÃ©es du bot.

10) utils/logger.py

Ã‰crit dans logs.txt :

message utilisateur

intent dÃ©tectÃ©

rÃ©ponse envoyÃ©e

â¡ï¸ TrÃ¨s utile pour dÃ©bug et analytics.

11) data/faq_corpus.json

FAQ structurÃ©e par catÃ©gories.

Exemple :
"livraison": [
  { "q": "...", "a": "..." }
]
â¡ï¸ Source de vÃ©ritÃ©.

12) data/intents.json

DÃ©finition des intents + mots-clÃ©s associÃ©s.

â¡ï¸ Pour le routing rapide non-IA.

ğŸ”¥ COMMENT LE PIPELINE FONCTIONNE EXACTEMENT
ğŸ”„ Ã‰tape 0 : Tiledesk â†’ webhook â†’ FastAPI

Le message arrive sous forme :

{
  "text": "OÃ¹ est mon colis ?"
}

Lien webhook :

POST /tiledesk/message

ğŸ”„ Ã‰tape 1 : Extraction du message

chatbot.py rÃ©cupÃ¨re :

user_message = payload.get("text") or ...

ğŸ”„ Ã‰tape 2 : Keyword matching (rapide, non IA)

Ex :

"colis"

"livraison"

â†’ match immÃ©diat â†’ intent = livraison

Si pas de match, on va Ã  lâ€™Ã©tape suivante.

ğŸ”„ Ã‰tape 3 : Intent classifier IA (GPT-4o-mini)

Le LLM reÃ§oit :
"Voici la liste des intents... Donne 1 intent pour : 'Jâ€™ai cassÃ© ma raquette'"

Il rÃ©pond :
garantie

â¡ï¸ Lâ€™IA intervient ici uniquement si le matcher a Ã©chouÃ©.

ğŸ”„ Ã‰tape 4 : FAQ responder IA (GPT-4o-mini)

On envoie au modÃ¨le :

la liste des (q,a) du bon intent

le message utilisateur

Et il doit sÃ©lectionner la bonne rÃ©ponse, sans inventer.

â¡ï¸ Lâ€™IA intervient ici pour gÃ©nÃ©rer la rÃ©ponse finale, mais en utilisant uniquement le contenu du JSON.

ğŸ”„ Ã‰tape 5 : Fallback IA (si aucune rÃ©ponse trouvÃ©e)

Lâ€™IA rÃ©dige :

â€œJe ne trouve pas encore cette information, pouvez-vous prÃ©ciser votre demande ?â€

â¡ï¸ Lâ€™IA intervient ici comme filet de sÃ©curitÃ©.

ğŸ”„ Ã‰tape 6 : Envoi au frontend Tiledesk

FastAPI renvoie :
{
  "text": "Vous pouvez suivre votre colis grÃ¢ce au lien reÃ§u dans lâ€™email dâ€™expÃ©dition."
}

Tiledesk lâ€™affiche dans le widget.

ğŸ¯ RÃ©sumÃ© clair : quand intervient lâ€™IA ?
Ã‰tape	IA utilisÃ©e ?	RÃ´le
Keywords matcher	âŒ Non	Ultra rapide, regex
Intent classifier	âœ… Oui	Comprendre lâ€™intention
FAQ responder	âœ… Oui	Choisir la meilleure rÃ©ponse parmi JSON
Fallback	âœ… Oui	RÃ©ponse neutre et polie
Envoi rÃ©ponse	âŒ Non	Simple routage


ğŸš€ Conclusion : Vue dâ€™ensemble

Ton backend Phase 1 :

reÃ§oit un message

identifie lâ€™intent

sÃ©lectionne la rÃ©ponse la plus pertinente dans la FAQ

utilise lâ€™IA uniquement si nÃ©cessaire

renvoie une rÃ©ponse propre, courte, professionnelle

prÃ©pare le terrain pour les phases 2 / 3 (garantie & retours)

sera compatible Phase 4 (RAG produit)

Tu as maintenant une architecture professionnelle, claire, et scalable.
